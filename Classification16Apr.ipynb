{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_python import *\n",
    "from data_preprocess import * \n",
    "from textblob import TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweetdata=pd.read_csv(\"data/trumptweets.csv\")\n",
    "tweetdata['date'] = pd.to_datetime(tweetdata['date'])\n",
    "tweetdata['time'] = tweetdata['date'].dt.time\n",
    "tweetdata['hour'] = tweetdata['date'].dt.strftime('%H')\n",
    "tweetdata['min'] = tweetdata['date'].dt.strftime('%M')\n",
    "tweetdata['hour']=pd.to_numeric(tweetdata['hour'])\n",
    "tweetdata['min']=pd.to_numeric(tweetdata['min'])\n",
    "tweetdata['hour']=tweetdata['hour']+(tweetdata['min'])/60\n",
    "tweetdata['date'] = pd.to_datetime(tweetdata['date']).dt.strftime('%m/%d/%Y')\n",
    "tre_rate_data=pd.read_table(\"data/YieldCurve.txt\",sep=\"\\t\")\n",
    "tre_rate_data['Date'] = pd.to_datetime(tre_rate_data['Date']).dt.strftime('%m/%d/%Y')\n",
    "Tweet_rate_new = pd.merge(left=tweetdata , right=tre_rate_data, left_on='date', right_on='Date')\n",
    "Tweet_rate_new=Tweet_rate_new.drop(['id','link','retweets','favorites','mentions','hashtags','geo','Date','min','time'],axis=1)\n",
    "import numpy as np\n",
    "df1=np.array(Tweet_rate_new['1 Mo'])\n",
    "df1_log=[]\n",
    "for x in range(len(df1)-1):\n",
    "    if Tweet_rate_new['hour'][x]>15:\n",
    "        if df1[x+1]>df1[x]:\n",
    "            df1_log.append('up')\n",
    "        elif df1[x+1]<df1[x]:\n",
    "            df1_log.append('down')\n",
    "        else:\n",
    "            df1_log.append('neutral')\n",
    "    else:\n",
    "        if df1[x]>df1[x-1]:\n",
    "            df1_log.append('up')\n",
    "        elif df1[x]<df1[x-1]:\n",
    "            df1_log.append('down')\n",
    "        else:\n",
    "            df1_log.append('neutral')\n",
    "df11_log=df1[1:]-df1[:-1]\n",
    "Tweet_rate_new=Tweet_rate_new[1:]\n",
    "Tweet_rate_new['Label']=df1_log\n",
    "Tweet_rate_new['1 Mo pric diff']=df11_log\n",
    "Tweet_rate_new = Tweet_rate_new[['date','hour','content','1 Mo','Label','1 Mo pric diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_rate=Tweet_rate_new\n",
    "# Load the regular expression library\n",
    "import re\n",
    "# Remove punctuation\n",
    "Tweet_rate['content_processed'] = Tweet_rate['content'].map(lambda x: re.sub('[^\\\\w\\\\s]', ' ', x))\n",
    "# Convert the titles to lowercase\n",
    "Tweet_rate['content_processed'] = Tweet_rate['content_processed'].map(lambda x: x.lower())\n",
    "\n",
    "'''\n",
    "clean the text in a tweet by removing links and special characters using regex.\n",
    "'''\n",
    "Tweet_rate['content_processed'] = Tweet_rate['content_processed'].map(lambda x: ' '.join(re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", x).split()))\n",
    "  \n",
    "# Remove stopwords\n",
    "with open(\"./data/stopwords.txt\") as f:\n",
    "    stopwords = f.read()\n",
    "Tweet_rate['content_processed'] = [' '.join([w for w in doc.split(\" \") if w not in stopwords]) for doc in Tweet_rate['content_processed']]\n",
    "\n",
    "# Lemmatization \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "Tweet_rate['content_processed'] = [' '.join([lemmatizer.lemmatize(w) for w in doc.split(\" \")]) for doc in Tweet_rate['content_processed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "      <th>content_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/05/2009</td>\n",
       "      <td>neutral</td>\n",
       "      <td>appearing view tomorrow morning discus celebri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/08/2009</td>\n",
       "      <td>neutral</td>\n",
       "      <td>read top financial tip david letterman tinyurl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/08/2009</td>\n",
       "      <td>neutral</td>\n",
       "      <td>blog post celebrity apprentice finale lesson l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/12/2009</td>\n",
       "      <td>up</td>\n",
       "      <td>persona wallflower build wall cling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05/12/2009</td>\n",
       "      <td>neutral</td>\n",
       "      <td>miss usa tara conner fired believer chance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    Label                                  content_processed\n",
       "1  05/05/2009  neutral  appearing view tomorrow morning discus celebri...\n",
       "2  05/08/2009  neutral  read top financial tip david letterman tinyurl...\n",
       "3  05/08/2009  neutral  blog post celebrity apprentice finale lesson l...\n",
       "4  05/12/2009       up                persona wallflower build wall cling\n",
       "5  05/12/2009  neutral         miss usa tara conner fired believer chance"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = Tweet_rate[[\"date\", \"Label\", 'content_processed']]\n",
    "len(df_data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\ISSS617-Python\\Project-python\\data_preprocess.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[CLEAN_COL] = clean_col(df[column])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "C:\\Users\\User\\Documents\\ISSS617-Python\\Project-python\\data_preprocess.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['polarity'] = df[column].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
      "C:\\Users\\User\\Documents\\ISSS617-Python\\Project-python\\data_preprocess.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['subjectivity'] = df[column].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n"
     ]
    }
   ],
   "source": [
    "df_data = data_preprocess(df_data, 'content_processed', clean_data=True, remove_stopwords=False, sentiment=True, stem_lemma=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Split (based on date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_data[22500:29000]\n",
    "test_df = df_data[29000: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "      <th>content_processed</th>\n",
       "      <th>clean_data</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22503</th>\n",
       "      <td>12/24/2015</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hillary deplore tone inflammatory rhetoric cam...</td>\n",
       "      <td>hillary deplore tone inflammatory rhetoric cam...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22504</th>\n",
       "      <td>12/24/2015</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ihatematt hillary allowed run criminal question</td>\n",
       "      <td>ihatematt hillary allowed run criminal question</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22505</th>\n",
       "      <td>12/24/2015</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ihatematt hillary allowed run criminal</td>\n",
       "      <td>ihatematt hillary allowed run criminal</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22506</th>\n",
       "      <td>12/24/2015</td>\n",
       "      <td>neutral</td>\n",
       "      <td>christmas movie perfect tbt makeamericagreatag...</td>\n",
       "      <td>christmas movie perfect tbt makeamericagreatag...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22507</th>\n",
       "      <td>12/24/2015</td>\n",
       "      <td>neutral</td>\n",
       "      <td>classyexplorer gatewaypundit jim fail mention ...</td>\n",
       "      <td>classyexplorer gatewaypundit jim fail mention ...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    Label                                  content_processed  \\\n",
       "22503  12/24/2015  neutral  hillary deplore tone inflammatory rhetoric cam...   \n",
       "22504  12/24/2015  neutral    ihatematt hillary allowed run criminal question   \n",
       "22505  12/24/2015  neutral             ihatematt hillary allowed run criminal   \n",
       "22506  12/24/2015  neutral  christmas movie perfect tbt makeamericagreatag...   \n",
       "22507  12/24/2015  neutral  classyexplorer gatewaypundit jim fail mention ...   \n",
       "\n",
       "                                              clean_data  polarity  \\\n",
       "22503  hillary deplore tone inflammatory rhetoric cam...      -0.6   \n",
       "22504    ihatematt hillary allowed run criminal question      -0.4   \n",
       "22505             ihatematt hillary allowed run criminal      -0.4   \n",
       "22506  christmas movie perfect tbt makeamericagreatag...       1.0   \n",
       "22507  classyexplorer gatewaypundit jim fail mention ...      -0.5   \n",
       "\n",
       "       subjectivity  \n",
       "22503          1.00  \n",
       "22504          0.55  \n",
       "22505          0.55  \n",
       "22506          1.00  \n",
       "22507          0.30  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n",
      "3467\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data distribution:\n",
      " neutral    5419\n",
      "up          547\n",
      "down        534\n",
      "Name: Label, dtype: int64\n",
      "test data distribution:\n",
      " neutral    3021\n",
      "down        272\n",
      "up          174\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('train data distribution:\\n', train_df.Label.value_counts())\n",
    "print('test data distribution:\\n', test_df.Label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6500, 21)\n",
      "(6500, 23)\n",
      "(6500, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\ISSS617-Python\\Project-python\\model_python.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['polarity'] = df[column].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
      "C:\\Users\\User\\Documents\\ISSS617-Python\\Project-python\\model_python.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['subjectivity'] = df[column].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n"
     ]
    }
   ],
   "source": [
    "train_data, transform = data_vect_fit(train_df, CLEAN_COL, sentiment=True,topic_vect=True)\n",
    "test_data = data_vect_transform(test_df, CLEAN_COL, transform )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_df['Label']\n",
    "test_label = test_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (6500, 43)\n",
      "testing data shape:  (3467, 43)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data shape: \", train_data.shape)\n",
    "print(\"testing data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest results: \n",
      "training accuracy:  0.9732307692307692\n",
      "testing accuracy:  0.8641476781078743\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-54150abd5ffb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'random forest results: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_fit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\ISSS617-Python\\Project-python\\model_python.py\u001b[0m in \u001b[0;36mmodel_fit_predict\u001b[1;34m(clf, train_data, train_label, test_data, test_label)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtest_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtest_predict_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"testing auc score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    353\u001b[0m     return _average_binary_score(\n\u001b[0;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "print('random forest results: ')\n",
    "clf = model_fit_predict(clf, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_idf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-ac26e7c78126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_idf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.predict_proba(tf_idf.transform([test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import save_transform\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'rf.m')\n",
    "save_transform(transform, 'transform.m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
